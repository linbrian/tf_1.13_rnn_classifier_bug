{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_columns(vocab_size, embedding_dim):\n",
    "    \"\"\"\n",
    "    return the feature columns which are inferred from the feature and dict path.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    column = tf.feature_column.categorical_column_with_identity(key=\"text\",\n",
    "                                                                             num_buckets=vocab_size)\n",
    "    feature_columns = [tf.feature_column.embedding_column(categorical_column=column, dimension=embedding_dim)]\n",
    "    return feature_columns\n",
    "\n",
    "def text_line_dataset(dataset_path, vocab_dictionary_path, vocab_size, batch_size=64, repeat_count=50, shuffle=True):\n",
    "    \"\"\"\n",
    "    Efficient and streaming way of reading records line by line from the given dataset path.\n",
    "\n",
    "    :param dataset_path:\n",
    "    :param batch_size:\n",
    "    :param repeat_count:\n",
    "    :param shuffle:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataset = tf.data.TextLineDataset(dataset_path)\n",
    "\n",
    "    index_table_from_file = tf.contrib.lookup.index_table_from_file(vocab_dictionary_path,\n",
    "                                                                    default_value = vocab_size - 1,\n",
    "                                                                    key_column_index=0)\n",
    "\n",
    "    # convert every line to features with batching and repetition\n",
    "    dataset = dataset.map(\n",
    "        lambda line: to_feature_label_for_train_dev(line, index_table_from_file))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "    dataset = dataset.repeat(repeat_count).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "def to_feature_label_for_train_dev(input, index_table_from_file):\n",
    "    \"\"\"\n",
    "    returns feature, label for training\n",
    "    :param input:\n",
    "    :param index_table_from_file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    input_split = tf.string_split([input], \"|\").values\n",
    "    feature = to_feature(input_split, index_table_from_file)\n",
    "    # labels must be string type and have any value in label_vocabulary\n",
    "    label = input_split[-1]\n",
    "    return feature, label\n",
    "\n",
    "\n",
    "def to_feature(input, lookup_table: tf.contrib.lookup.LookupInterface, export=False):\n",
    "    \"\"\"\n",
    "    returns map of {categorical_feature -> sparse tensor where tokens converted into indices using lookup\n",
    "                    numerical_feature -> numerical tensor}\n",
    "    :param input:\n",
    "    :param lookup_table:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    feature = {}\n",
    "    if export:\n",
    "        split_string = tf.string_split(input[0], delimiter=\" \")\n",
    "    else:\n",
    "        split_string = tf.string_split([input[0]], delimiter=\" \")\n",
    "    sparse_tensor = tf.SparseTensor(indices=split_string.indices,\n",
    "                                    values=split_string.values,\n",
    "                                    dense_shape=split_string.dense_shape)\n",
    "\n",
    "    feature[\"text\"] = lookup_table.lookup(sparse_tensor)  # generate indexes for vocabularies\n",
    "    return feature\n",
    "\n",
    "\n",
    "def serving_input_receiver_fn_decorator(vocab_dictionary_path, vocab_size):\n",
    "\n",
    "    def serving_input_receiver_fn():\n",
    "        \"\"\"\n",
    "        serialization function to convert models to tf saved model format\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        csv_row = tf.placeholder(dtype=tf.string, shape=[None], name='input_csv_tensor')\n",
    "        receiver_tensors = {'input': csv_row}\n",
    "        #one feature in toy example\n",
    "        default_values_for_csv = [[''] for i in range(1)]\n",
    "        columns = tf.decode_csv(csv_row, default_values_for_csv, \"\\t\", use_quote_delim=False)\n",
    "\n",
    "        index_table_from_file = tf.contrib.lookup.index_table_from_file(vocab_dictionary_path,\n",
    "                                                                        default_value= vocab_size - 1, \n",
    "                                                                        key_column_index=0)\n",
    "\n",
    "        return tf.estimator.export.ServingInputReceiver(\n",
    "            to_feature(columns, index_table_from_file, export=True),\n",
    "            receiver_tensors)\n",
    "\n",
    "    return serving_input_receiver_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dictionary_path = \"dict_example.txt\"\n",
    "train_path = \"train_example.txt\"\n",
    "dev_path = \"dev_example.txt\"\n",
    "with open(vocab_dictionary_path, \"r\") as f:\n",
    "    vocab_size = len(f.readlines()) + 1 #+1 for unknown  \n",
    "embedding_dim = 2\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns(vocab_size, embedding_dim),\n",
    "                                                model_dir=\"test_model_dnn\",\n",
    "                                                hidden_units=[64],\n",
    "                                                n_classes=3,\n",
    "                                                label_vocabulary=[\"positive\", \"negative\", \"neutral\"],\n",
    "                                                )\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=lambda: text_line_dataset(dataset_path = train_path, \n",
    "                                       vocab_dictionary_path = vocab_dictionary_path, \n",
    "                                       vocab_size = vocab_size,\n",
    "                                       batch_size = 4, \n",
    "                                       repeat_count = 10),\n",
    "                                       max_steps=1000) \n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=lambda: text_line_dataset(dataset_path = dev_path, \n",
    "                                               vocab_dictionary_path = vocab_dictionary_path,\n",
    "                                               vocab_size = vocab_size,\n",
    "                                               batch_size = 2048, \n",
    "                                               repeat_count = 1, \n",
    "                                               shuffle = False), \n",
    "                                               steps=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_model_predictions = classifier.predict(input_fn=lambda: text_line_dataset(dataset_path = dev_path, \n",
    "                                               vocab_dictionary_path = vocab_dictionary_path,\n",
    "                                               vocab_size = vocab_size,\n",
    "                                               batch_size = 2048, \n",
    "                                               repeat_count = 1, \n",
    "                                               shuffle = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in estimator_model_predictions:\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    \"\"\"\n",
    "    Inference object which initializes a tensorflow saved model and provides predict API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, saved_model_dir):\n",
    "        self.sess = tf.Session(graph=tf.Graph())\n",
    "        for m in tf.gfile.ListDirectory(saved_model_dir):\n",
    "            if m != 'variables' and tf.gfile.IsDirectory(saved_model_dir + '/' + m):\n",
    "                print('Using Saved Folder version: %s' % (m))\n",
    "                saved_model_dir = saved_model_dir + '/' + m\n",
    "        metagraph = tf.saved_model.loader.load(self.sess, [tf.saved_model.tag_constants.SERVING], saved_model_dir)\n",
    "\n",
    "        self.output_score_field_name = dict(metagraph.signature_def['serving_default'].outputs)['scores'].name\n",
    "        self.output_classes_field_name = dict(metagraph.signature_def['serving_default'].outputs)['classes'].name\n",
    "        self.input_field_name = dict(metagraph.signature_def['serving_default'].inputs)['inputs'].name\n",
    "\n",
    "    def predict(self, input):\n",
    "        return self.sess.run([self.output_score_field_name, self.output_classes_field_name],\n",
    "                             feed_dict={\n",
    "                                 self.input_field_name: [input]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.export_saved_model(\"savedmodel_dnn\", \n",
    "                              serving_input_receiver_fn=serving_input_receiver_fn_decorator(\n",
    "                                     vocab_dictionary_path = vocab_dictionary_path,\n",
    "                                     vocab_size = vocab_size)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = Inference(\"savedmodel_dnn\")\n",
    "with open(dev_path) as f:\n",
    "    for line in f.readlines():\n",
    "        text = line.split(\"|\")[0]\n",
    "        label = line.split(\"|\")[1][:-1]\n",
    "        prediction = saved_model.predict(text)\n",
    "        print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1_13",
   "language": "python",
   "name": "tf1_13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
